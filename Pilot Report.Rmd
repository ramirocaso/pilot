---
title: "Pilot Study Results"
author: "Ramiro Casó - Rotterdam School of Management"
date: "`r Sys.Date()`"
output:
  html_document:
    css: custom.css
    theme: journal
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE, fig.align='center'}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
options(knitr.table.format = "html")
```

```{r libraries}
library(kableExtra)
library(knitr)
library(tidyverse) # Includes ggplot2, dplyr, and other data manipulation libraries
library(readr)
library(rstatix)
library(ggpubr)
library(emmeans)
library(lmtest)
library(tidyr)
library(RColorBrewer)
```

# Intro

Hello Bram, Steven, how are you?

I've just wrapped up the analysis on the subjective knowledge scale, and I wanted to share something that I think might be interesting. At the end of this report are the details, but as an intro, here is a summary: 

**The Analysis:**

In line with our last meeting, I've implemented the controls you suggested, such as subtracting the values for Time 1 (T1) and using them as a control variable. I also combined both batches of participants—with and without visual aid—and incorporated them as another control variable.

**Main Findings:**

Here's the main finding so far:

- Understanding of Metabolism: Regardless of the text type, participants seemed to feel they understood metabolism better after reading explanatory text. This is seen in the rise in perceived understanding from T1 to T2 then its reversal after objective knowledge testing at T3.
- Metaphors Matter: An extended apt metaphor seemed to have a slight but noticeable effect compared to a non-apt metaphor. This could indicate that metaphors enhance subjective knowledge, and the aptness of the metaphor might further amplify this effect.

**Thoughts and Recommendations:**

I think our Objective Knowledge measure might need a revamp. While it did have a moderate effect, I feel it didn't quite shatter the illusion of knowing as we hope it would. Perhaps asking participants to explain what they just read could yield a stronger effect, similar to what Fernbach does in his studies. If apt metaphors indeed increase subjective knowledge, participants in that condition may resist this illusion-shattering more robustly.

I hope these insights make sense. Obviously,your thoughts and suggestions on the analysis below are more than welcome! 

**Moving Forward:**

I'll continue to analyse the remaining variables, but I wanted to get this to you quickly, as we might still have time to gather new data.

That's all for now. I'm looking forward to hearing your thoughts.

¡Saludos!

Ramiro

**p.s:** You probably already noticed it, but the menu in the top left side of the page helps you navigate through the report. It seemed like a lot of work to make the report, but it wasn't, and I believe it could be a better way to share results with you hereafter. So also, let me know what you think about this "new method" of reporting ;)  

------------------------------------------------------------------------

```{r loading the data}
exp_data <- read_csv("study2b_total.csv")
exp_data[, c(46, 51, 56)] <- lapply(exp_data[, c(46, 51, 56)], as.factor)
```

# Data Cleaning

First, and just like you suggested, I'm using the two batches together and included a new variable called `pilot`, which differentiates the first batch (pilot_a = with visual aid) from the second batch (pilot_b = without visual aid)

Second, I'm removing participants that either answered too fast (below 5 minutes) or took too long (above 25 minutes).

Here is a histogram of `duration_min` along with the summary statistics.

---

```{r cleaning}

ggplot(exp_data, aes(x = duration_min)) +
  geom_histogram(binwidth = 2, fill = "blue", alpha = 0.7) +
  labs(title = "Duration in Min",
       x = "Duration (Minutes)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) # Center the title


# Calculate the summary statistics
duration_summary <- summary(exp_data$duration_min)

# Create a data frame to hold the summary
summary_df <- data.frame(
  Statistic = c("Minimum", "1st Quartile", "Median", "Mean", "3rd Quartile", "Maximum"),
  Value = c(duration_summary[1], duration_summary[2], duration_summary[3], mean(exp_data$duration_min), duration_summary[5], duration_summary[6])
)

# Round the values to 2 decimal points
summary_df$Value <- round(summary_df$Value, 2)

kable(summary_df, format = "html", caption = "Summary of Duration (Minutes)", align = c("c", "c"), row.names = FALSE)


```

---

As can be observed, a few observations clearly did not take the survey seriously. I'm trimming all participants whose duration is below 4 minutes and above 20 minutes.

Here are the resulting histogram and descriptives of `duration_min` after the removal of observations. 

---

```{r triming}


# Calculate the 5th and 95th percentiles of duration_min
#lower_bound <- quantile(exp_data$duration_min, 0.10)
#upper_bound <- quantile(exp_data$duration_min, 0.90)

lower_bound <- 4  # Lower bound set to 4 minutes
upper_bound <- 20 # Upper bound set to 20 minutes


# Filter the data to retain only observations between the 5th and 95th percentiles
exp_data_t <- exp_data[exp_data$duration_min > lower_bound & exp_data$duration_min < upper_bound, ]

#exp_data_t <- exp_data[exp_data$duration_min > lower_bound & exp_data$duration_min < upper_bound & exp_data$pilot == "pilot_b", ]

ggplot(exp_data_t, aes(x = duration_min)) +
  geom_histogram(binwidth = 2, fill = "blue", alpha = 0.7) +
  labs(title = "Duration in Min",
       x = "Duration (Minutes)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) # Center the title

# Calculate the summary statistics
duration_summary <- summary(exp_data_t$duration_min)

# Create a data frame to hold the summary
summary_df <- data.frame(
  Statistic = c("Minimum", "1st Quartile", "Median", "Mean", "3rd Quartile", "Maximum"),
  Value = c(duration_summary[1], duration_summary[2], duration_summary[3], mean(exp_data_t$duration_min), duration_summary[5], duration_summary[6])
)

# Round the values to 2 decimal points
summary_df$Value <- round(summary_df$Value, 2)

kable(summary_df, format = "html", caption = "Summary of Duration (Minutes)", align = c("c", "c"), row.names = FALSE)



```

---

The new minimum duration is `r round(min(exp_data_t$duration_min), 2)`

The new maximum duration is `r round(max(exp_data_t$duration_min), 2)`

This reduces the data set to a total of `r nrow(exp_data_t)` observations. 

---

# Descriptives


With the clean data, here is a table with the mean, standard deviation, and number of observations of the main variables. . 

For clarity, these are the names of the variables.

- `text_type`: The main independent variable indicating the type of text that was presented, which has three levels:
  - `met_a` = metaphor apt;
  - `met_na` = non-apt metaphor;
  - `literal` = control condition.
- `ave_sk_t1`: Mean Subjective Knowledge before presenting the Text (Time 1).
- `ave_sk_t2`: Mean Subjective Knowledge after presenting the Text (Time 2).
- `ave_sk_t3`: Mean Subjective Knowledge after presenting the Objective Knowledge Scale (Time 3).
- `ave_wta`: Average of the Willingness to Adopt scale.
- `total_ok`: Results of Objective Knowledge Scale calculated by adding the correct
- `duration_min`: Average time it took to complete the survey in minutes.

---

```{r descriptives}

# Compute means and standard errors

variables <- c("ave_sk_t1", "ave_sk_t2", "ave_sk_t3","total_ok","ave_wta", "duration_min")

data_summary <- exp_data_t %>%
  gather(variable, value, all_of(variables)) %>% # Using all_of for variable selection
  group_by(variable) %>% # Grouping by variable only
  summarise(
    mean = mean(value, na.rm = TRUE),
    se = sd(value, na.rm = TRUE) / sqrt(n()),
    p10 = quantile(value, 0.10, na.rm = TRUE), # 10th percentile
    p25 = quantile(value, 0.25, na.rm = TRUE), # 25th percentile
    p50 = quantile(value, 0.50, na.rm = TRUE), # 50th percentile (median)
    p75 = quantile(value, 0.75, na.rm = TRUE), # 75th percentile
    n = n()
  )

data_summary_grouped <- exp_data_t %>%
  gather(variable, value, all_of(variables)) %>% # Using all_of for variable selection
  group_by(text_type, variable) %>%
  summarise(
    mean = mean(value, na.rm = TRUE),
    se = sd(value, na.rm = TRUE) / sqrt(n()),
    p10 = quantile(value, 0.10, na.rm = TRUE), # 10th percentile
    p25 = quantile(value, 0.25, na.rm = TRUE), # 25th percentile
    p50 = quantile(value, 0.50, na.rm = TRUE), # 50th percentile (median)
    p75 = quantile(value, 0.75, na.rm = TRUE), # 75th percentile
    n = n()
  )

## First table

data_summary %>%
  kable(format = "html", digits = 2, align = 'c', caption = "Summary Statistics for All Variables") %>%
  kable_styling(full_width = FALSE)

# Creating a table for data_summary_grouped
data_summary_grouped %>%
  kable(format = "html", digits = 2, align = 'c', caption = "Summary Statistics for Groped Variables") %>%
  kable_styling(full_width = FALSE)


```

After the trim, we end up with more than 30 observations per condition. This, however, will change ahead, since the the variable `pilot` which I used to differentiate the two badges **did have an effect** on some of the analysis

The following sections explore each variable in detail. 

--- 

# Subjective Knowledge

Let's analyze it, starting with the subjective knowledge scale.

Again, for clarity, keep in mind that:

- `ave_sk_t1`: Mean Subjective Knowledge before presenting the Text (Time 1).
- `ave_sk_t2`: Mean Subjective Knowledge after presenting the Text (Time 2).
- `ave_sk_t3`: Mean Subjective Knowledge after presenting the Objective Knowledge Scale (Time 3).
- `delta_sk2_sk1`: The difference between `ave_sk_t2` and `ave_sk_t1`
- `delta_sk3_sk2`: The difference between `ave_sk_t3` and `ave_sk_t2`
- `delta_sk3_sk1`: The difference between `ave_sk_t3` and `ave_sk_t1`

## SK ANOVA's

First, let's run a simple Repeated measured ANOVA. I'm including the variable `pilot`as a covariate, as you can see in the code below.

---

```{r sk dataframes}

sk_df <- exp_data_t %>%
  select(ResponseId, ave_sk_t1, ave_sk_t2, ave_sk_t3, text_type, pilot) %>%
  pivot_longer(
    cols = c(ave_sk_t1, ave_sk_t2, ave_sk_t3),
    names_to = "sk_time",
    values_to = "ave_sk"
  )

sk_df2 <- exp_data_t %>%
  select(ResponseId, text_type,ave_sk_t1, ave_sk_t2, ave_sk_t3, delta_sk2_sk1, delta_sk3_sk2, delta_sk3_sk1, pilot) %>%
  mutate(delta_sk2_sk1_sq = delta_sk2_sk1^2,
         delta_sk3_sk2_sq = delta_sk3_sk2^2,
         delta_sk3_sk1_sq = delta_sk3_sk1^2)

sk_df3 <- exp_data_t %>%
  select(ResponseId, ave_sk_t1, ave_sk_t2, ave_sk_t3, text_type, pilot) 
```

```{r sk anova with control, echo=TRUE}

# Conduct the repeated measures ANOVA
anova_sk <- aov(ave_sk ~ sk_time + pilot + Error(ResponseId/sk_time), data = sk_df)
#anova_sk <- aov(ave_sk ~ sk_time + Error(ResponseId/sk_time), data = sk_df)


# Print the summary
summary(anova_sk)

```

If I'm reading the output correctly, `pilot` didn't have an effect on Subjective Knowledge. In that sense, we can keep the whole data set.

Below we can see a table with the means per condition, a line graph that show the results and the post-hoc analysis 

---

```{r sk ANOVA, fig.align='center'}

# Calculate the means and standard errors
sk_summary <- sk_df %>%
  group_by(sk_time) %>%
  summarise(
    n_obs = n(),
    mean_ave_sk = mean(ave_sk, na.rm = TRUE),
    se_ave_sk = sd(ave_sk, na.rm = TRUE) / sqrt(n()),
    .groups = "drop" # This line avoids a warning message
  )

# Formatting the table with kable and kableExtra
sk_summary %>%
  kable("html") %>%
  kable_styling("striped", full_width = FALSE) %>%
  add_header_above(c("Time Point" = 1, "Number of Observations" = 1, "Subjective Knowledge" = 2)) %>%
  column_spec(2:3, bold = TRUE, color = "blue")


# Create the plot
ggplot(sk_summary, aes(x=sk_time, y=mean_ave_sk, group=1)) +
  geom_line(color="blue") + # Line connecting the points
  geom_point(size=3, color="red") + # Points for the means
  geom_errorbar(aes(ymin=mean_ave_sk - se_ave_sk, ymax=mean_ave_sk + se_ave_sk), width=0.2) + # Error bars
  labs(
    title="Effect of SK Time on Average SK",
    x="SK Time",
    y="Average SK"
  ) +
  ylim(1, 7) + # Set the limits of the Y-axis
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) # Center the title


# Obtain the estimated marginal means
emm <- emmeans(anova_sk, ~ sk_time)

# Perform pairwise comparisons with Tukey adjustments
pairs <- pairs(emm, adjust = "tukey")

# Print the results
print(pairs)

```

Looking at the plot, it is clear (as we saw) that the differences are due to the lower scores in the first measure of SK. 

It seems that regardless of the experimental text, participants increased their SK after being presented with the text. There is a slight decrease in SK for time 3, that goes from 5.28 to 5.06, which seems to be moderately significant, according to the post-hoc analysis. 

In other words, without accounting for the experimental stimuli, participants first increased their **Subjective Knowledge** after being presented with the text and decrease it after being asked to complete the **Objective Knowledge** scale. 

Next, I conducted a mixed two-way ANOVA

---

## Mixed two-way ANOVA 

```{r sk mixed anova}
# Load the necessary libraries
library(nlme)
library(car) # For Type III SS

# Ensure that sk_time and text_type are factors
sk_df$sk_time <- factor(sk_df$sk_time)
sk_df$text_type <- factor(sk_df$text_type)
sk_df <- na.omit(sk_df)

# Fit the model with sk_time as a within-subjects factor, text_type as a between-subjects factor, and a random intercept for each subject

#model <- lme(ave_sk ~ text_type * sk_time, random = ~1 | ResponseId, data = sk_df)

model <- lme(ave_sk ~ text_type * sk_time + pilot, random = ~1 | ResponseId, data = sk_df)

# Use the Anova function from the car package to get Type III SS
mix_anova_sk <- Anova(model, type = "III")

# Print the result
print(mix_anova_sk)

```

the results indicate that both `text_type` and `sk_time` have significant main effects on the response variable `ave_sk`, but their interaction is not significant. Again, the `pilot` variable does not have a significant effect.

Below are the table with the means, the plot and the posthoc test for the `text_type` and `sk_time` 
For ease of reading, I'm going to present the posthoc comparisons separately. 
---

```{r sk mixed anova visualization,  fig.align='center'}
# Calculate the means and standard errors for each combination of text_type and sk_time

sk_summary <- sk_df %>%
  group_by(text_type, sk_time) %>%
  summarise(
    n_obs = n(),
    mean_ave_sk = mean(ave_sk, na.rm = TRUE),
    se_ave_sk = sd(ave_sk, na.rm = TRUE) / sqrt(n()),
    .groups = "drop")

# Formatting the table with kable and kableExtra
sk_summary %>%
  kable("html") %>%
  kable_styling("striped", full_width = FALSE) %>%
  add_header_above(c(" " = 2, "Subjective Knowledge" = 3)) %>% # Corrected the number of columns
  column_spec(3:5, bold = TRUE, color = "blue") # Adjusted the column range

# Create the plot
ggplot(sk_summary, aes(x=sk_time, y=mean_ave_sk, group=text_type, color=text_type)) +
  geom_line(linewidth=1) + # Lines connecting the points
  geom_point(linewidth=3) + # Points for the means
  geom_errorbar(aes(ymin=mean_ave_sk - se_ave_sk, ymax=mean_ave_sk + se_ave_sk), width=0.2) + # Error bars
  labs(
    title="Effect of SK Time and Text Type on Average SK",
    x="SK Time",
    y="Average SK"
  ) +
  ylim(1, 7) + # Set the limits of the Y-axis
  theme_minimal() +
  scale_color_brewer(palette="Set1") + # Use a color palette for the different text types 
  theme(plot.title = element_text(hjust = 0.5)) # Center the title

```

---

<center>**Pairwise comparison just for text_type **.</center>

```{r}
emm_text_type <- emmeans(model, ~ text_type)
pairs_text_type <- pairs(emm_text_type, adjust = "tukey")
summary_pairs_text_type <- summary(pairs_text_type)
print(summary_pairs_text_type)
```


---

<center>**Pairwise comparison just for sk_time **.</center>


```{r}
emm_sk <- emmeans(model, ~ sk_time)
pairs_sk <- pairs(emm_sk, adjust = "tukey")
summary_pairs_sk <- summary(pairs_sk)
print(summary_pairs_sk)
```


These results, to me, are indicative that the stimuli are not working as intended. 

When we look at the effect of `sk_time` on `ave_sk`, it seems that presenting participants with an explicative text does not lead to the shattering of the illusion of knowing. Perhaps this is because participants aren't required to make any effort to explain how metabolism works but instead are **"passively"** consuming information that differs in format. In that sense, it is possible that participants feel that they have **"learned"** something, increasing their rating `ave_sk` instead of realizing they don't know much about the subject. 

This effect of `sk_time` on `ave_sk` is shown both in the highly significant coefficient as well as in the posthoc analysis. In the latter, all of the instances present significant difference, with the difference between T2 and T3 slightly less strong (p < 0.1). 

What this indicates is that indeed participants "gained" subjective knowledge when presented with the stimuli and then lost it after they were presented with the Objective Knowledge Scale. 

**This is VERY IMPORTANT (I believe)**

When we look at the effect of `text_type` on `ave_sk`, it seems that participants in the apt metaphor condition report slightly higher levels  of subjective knowledge than participants in the non-apt metaphor condition, although this is not reflected in the posthoc analysis. 

Now I'm going to perform the analysis using the deltas. 

## SK Deltas

First, let's take a look at the distribution of the Deltas. 

I'm including a squared version of each delta because I think it is better to handle negative values and, also, because it gives a greater weight to largers differences. The problem is that it distorts the distributions, so I'm not sure if it's a good idea. 

In any case, I'm doing both for you to consider. 

```{r deltas vis, fig.align='center'}

# Reshape the data into a long format
sk_df2_long <- sk_df2 %>%
  select(delta_sk2_sk1, delta_sk3_sk2, delta_sk3_sk1, delta_sk2_sk1_sq, delta_sk3_sk2_sq, delta_sk3_sk1_sq) %>%
  gather(key = "variable", value = "value")

# Create the faceted plot
ggplot(sk_df2_long, aes(x = value)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  facet_wrap(~ variable, scales = "free", ncol = 2) +
  labs(
    title = "Histograms of Deltas of Subjective Knowledge",
    x = "Value",
    y = "Frequency"
  ) +
  theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))

```

### SK Deltas without squaring 

Now, I want to know if there are differences in `delta_sk2_sk1`

```{r}
sk_df2 <- na.omit(sk_df2)
model_delta <- aov(delta_sk2_sk1 ~ text_type + pilot, data = sk_df2)
#model_delta <- aov(delta_sk2_sk1 ~ text_type, data = sk_df2)

summary(model_delta)


```

Here is the plot.

```{r, fig.align='center'}

# Calculate the means and standard errors
means_se <- sk_df2 %>%
  group_by(text_type) %>%
  summarise(
    mean_delta = mean(delta_sk2_sk1, na.rm = TRUE),
    se_delta = sd(delta_sk2_sk1, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Create the plot
ggplot(means_se, aes(x = text_type, y = mean_delta, group = 1)) +
  geom_line(color = "blue") + # Line connecting the points
  geom_point(size = 3, color = "red") + # Points for the means
  geom_errorbar(aes(ymin = mean_delta - se_delta, ymax = mean_delta + se_delta), width = 0.2) + # Error bars
  labs(
    title = "Effect of Text Type on Delta SK2 SK1",
    x = "Text Type",
    y = "Mean Delta SK2 SK1"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) # Center the title

```

### SK Deltas squaring. 

```{r}

model_delta_sq <- aov(delta_sk2_sk1_sq ~ text_type + pilot, data = sk_df2)
#model_delta_sq <- aov(delta_sk2_sk1_sq ~ text_type, data = sk_df2)

summary(model_delta_sq)

```

And here is the plot for the squared differences

```{r squared deltas, fig.align='center'}

# Calculate the means and standard errors
means_se <- sk_df2 %>%
  group_by(text_type) %>%
  summarise(
    mean_delta = mean(delta_sk2_sk1_sq, na.rm = TRUE),
    se_delta = sd(delta_sk2_sk1_sq, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Create the plot
ggplot(means_se, aes(x = text_type, y = mean_delta, group = 1)) +
  geom_line(color = "blue") + # Line connecting the points
  geom_point(size = 3, color = "red") + # Points for the means
  geom_errorbar(aes(ymin = mean_delta - se_delta, ymax = mean_delta + se_delta), width = 0.2) + # Error bars
  labs(
    title = "Effect of Text Type on Squared Delta SK2 SK1",
    x = "Text Type",
    y = "Mean Delta SK2 SK1"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) # Center the title

```

### ANOVA for av_sk_t2 controlling for av_sk_t1

Lastly, I want to see if there are differences in the average subjective knowledge reported in Time 2 (after the experimental stimuli was presented) controlling for the score of av_sk_t1 and pilot. 

```{r sk controlling, fig.align='center'}
# Fit the ANCOVA model
model_ancova <- lm(ave_sk_t2 ~ text_type + pilot + ave_sk_t1, data = sk_df3)

# Summary of the model
summary(model_ancova)

write.csv(sk_df3, "sk_df3.csv", col.names = FALSE)
```
```{r}

sk_df3 <- na.omit(sk_df3)

ancova_model <- lm(ave_sk_t2 ~ ave_sk_t1 + text_type + pilot, data = sk_df3)

text_type_levels <- levels(sk_df3$text_type)
colors <- brewer.pal(length(text_type_levels), "Set1")

for (pilot_level in unique(sk_df3$pilot)) {
  subset_data <- sk_df3[sk_df3$pilot == pilot_level,]
  plot(NULL, xlim=c(0.5, length(text_type_levels) + 0.5), ylim=range(subset_data$ave_sk_t2),
       xlab="Text Type", ylab="Average Subjective Knowledge at Time 2",
       main=paste("Relationship between ave_sk_t2 and text_type (", pilot_level, ")", sep=""),
       xaxt="n")
  axis(1, at=1:length(text_type_levels), labels=text_type_levels)
  for (i in 1:length(text_type_levels)) {
    points(rep(i, nrow(subset_data[subset_data$text_type == text_type_levels[i],])), 
           subset_data$ave_sk_t2[subset_data$text_type == text_type_levels[i]], col=colors[i], pch=16)
  }
  legend("topright", legend=text_type_levels, col=colors, pch=16, title="Text Type")
  
  # Adding the fitted line from the ANCOVA model
  lines(1:length(text_type_levels), 
        sapply(text_type_levels, function(tt) {
          predict(ancova_model, newdata=data.frame(ave_sk_t1=mean(subset_data$ave_sk_t1), 
                                                   text_type=tt, pilot=pilot_level))
        }), col="red", lwd=2)
}

```

---

As you can see, The coefficients for the `text_type` factor levels "met_a" and "met_na" are 0.0983 and -0.0230, respectively. Neither of these coefficients is statistically significant (p > 0.05)
so there is no evidence of a difference in `ave_sk_t2` across the `text_type` levels, after controlling for `ave_sk_t1` and `pilot`.

There is a mildly significant effect of `pilot` -0.27348 (p < 0.1). 

Finally, `ave_sk_t1` has a coefficient of 0.4230 which is highly significant (p < 0.01), which makes sense since we saw that the scores of SK are related to the scores at time 2. 


---

# Discussion of SK Scale. 

As I said before, I believe the stimuli are not working as predicted. 
Presenting participants with explanatory text, regardless of the type of text, seems to increase participants' perceived understanding of how metabolism work. 

When you think about it, this makes sense. 

Participants have no reason to feel their SK threatened in any way because their knowledge has not been tested yet. They probably think they know more since they have just acquired additional information. This effect is shown in the significant differences in SK between T1 and T2. Also, and perhaps more importantly, the difference between T2 and T3 is also significant, but in the opposite direction, meaning that after participants were asked to answer the Objective Knowledge Scale, their perceived understanding suffered. 

Finally, when the information is presented as an extended apt metaphor, it appears to have a more significant effect on SK than when presented with a non-apt extended metaphor. This effect is mild, but it could indicate that apt metaphors are better at increasing SK than non-apt metaphors.

# What to do next?

I believe we need to find a better way to shatter the illusion of knowing. Instead of using an Objective Knowledge scale, we could ask participants to explain, in their own words, what they've just read. Doing so will probably be difficult, especially for the literal condition. Therefore, we could expect a higher drop of SK from T2 to T3 in the literal and non-apt metaphors conditions. 






